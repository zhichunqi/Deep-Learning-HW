{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5, 6]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list\n",
    "[4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tuple\n",
    "(4,5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2, 3, 4, 5, 6, 7, 'd', 's'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sets\n",
    "{2,3,4,5,6,\"s\",\"d\",\"s\",4,7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dictionary\n",
    "d={\"a\":2,\"b\":5,\"c\":9}\n",
    "d[\"b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#loop and index\n",
    "for i in range(4):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0\n"
     ]
    }
   ],
   "source": [
    "#PyTorch\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a:\n",
      "tensor([1, 2, 3])\n",
      "type(a): <class 'torch.Tensor'>\n",
      "rank of a: 1\n",
      "a.shape: torch.Size([3])\n",
      "\n",
      "a[0]: tensor(1)\n",
      "type(a[0]): <class 'int'>\n",
      "\n",
      "a after mutating:\n",
      "tensor([ 1, 10,  3])\n"
     ]
    }
   ],
   "source": [
    "# Create a rank 1 tensor from a Python list\n",
    "a = torch.tensor([1,2,3])\n",
    "print ('Here is a:')\n",
    "print(a)\n",
    "print('type(a):',type(a))\n",
    "print('rank of a:',a.dim())\n",
    "print('a.shape:',a.shape)\n",
    "\n",
    "#Access elements using square brackets\n",
    "print()\n",
    "print('a[0]:',a[0])\n",
    "print('type(a[0]):',type(a[0].item()))\n",
    "\n",
    "#Mutate elements using square brackets\n",
    "a[1]=10\n",
    "print()\n",
    "print('a after mutating:')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is b:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "rank of b: 2\n",
      "b.shape: torch.Size([2, 3])\n",
      "\n",
      "b[0,1]: tensor(2)\n",
      "b[1,2]: tensor(6)\n",
      "\n",
      "a after mutating:\n",
      "tensor([[   1,    2,    3],\n",
      "        [   4, 1000,    6]])\n"
     ]
    }
   ],
   "source": [
    "# Create a two-dimensional tensor \n",
    "b= torch.tensor([[1,2,3],[4,5,6]])\n",
    "print ('Here is b:')\n",
    "print(b)\n",
    "print('rank of b:',b.dim())\n",
    "print('b.shape:',b.shape)\n",
    "\n",
    "#Access elements from a multidimensional tensor\n",
    "print()\n",
    "print('b[0,1]:',b[0,1])\n",
    "print('b[1,2]:',b[1,2])\n",
    "\n",
    "#Mutate elements of a multidimensional tensor\n",
    "b[1,1]=1000\n",
    "print()\n",
    "print('a after mutating:')\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor of zeros:\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      "tensor of ones:\n",
      "tensor([[1., 1.]])\n",
      "\n",
      "tensor matrix:\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "\n",
      "random tensor:\n",
      "tensor([[0.0878, 0.4673, 0.8756, 0.5894, 0.3757, 0.7529],\n",
      "        [0.0543, 0.4348, 0.9659, 0.6861, 0.9748, 0.3158],\n",
      "        [0.4606, 0.1280, 0.5095, 0.2364, 0.5711, 0.8712],\n",
      "        [0.0031, 0.2691, 0.7556, 0.2726, 0.2382, 0.1109],\n",
      "        [0.5091, 0.4566, 0.3392, 0.4177, 0.3374, 0.4066]])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor of all zeros\n",
    "a = torch.zeros(2,3)\n",
    "print('tensor of zeros:')\n",
    "print(a)\n",
    "\n",
    "#Create a tensor of all ones\n",
    "b = torch.ones(1,2)\n",
    "print('\\ntensor of ones:')\n",
    "print(b)\n",
    "\n",
    "#Create a 4x4 identity matrix\n",
    "c = torch.eye(4)\n",
    "print('\\ntensor matrix:')\n",
    "print(c)\n",
    "\n",
    "#Tensor of random values\n",
    "d = torch.rand(5,6)\n",
    "print('\\nrandom tensor:')\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datatype when torch choose for us:\n",
      "List of integers: torch.int64\n",
      "List of floats: torch.float32\n",
      "Mixed list: torch.float32\n",
      "\n",
      "datatype when we force a datatype:\n",
      "32-bit float: torch.float32\n",
      "32-bit integer: torch.int32\n",
      "64-bit integer: torch.int64\n"
     ]
    }
   ],
   "source": [
    "#Let torch choose the datatype\n",
    "x0 = torch.tensor([1,2])#List of integers\n",
    "x1 = torch.tensor([1.,2.,])#List of floats\n",
    "x2 = torch.tensor([1.,2])#Mixed list\n",
    "print('datatype when torch choose for us:')\n",
    "print('List of integers:', x0.dtype)\n",
    "print('List of floats:', x1.dtype)\n",
    "print('Mixed list:', x2.dtype)\n",
    "\n",
    "#Force a particular datatype\n",
    "y0 = torch.tensor([1,2], dtype=torch.float32)#32-bit float\n",
    "y1 = torch.tensor([1,2], dtype=torch.int32)#32-bit(signed) integer\n",
    "y2 = torch.tensor([1,2], dtype=torch.int64)#64-bit(signed) integer\n",
    "print('\\ndatatype when we force a datatype:')\n",
    "print('32-bit float:', y0.dtype)\n",
    "print('32-bit integer:', y1.dtype)\n",
    "print('64-bit integer:', y2.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0: torch.int64\n",
      "x1: torch.float32\n",
      "x2: torch.float64\n",
      "x3: torch.float32\n",
      "x4: torch.float64\n"
     ]
    }
   ],
   "source": [
    "x0 = torch.eye(3, dtype = torch.int64)\n",
    "x1 = x0.float() #Cast to 32-bit float\n",
    "x2 = x0.double()#Cast to 64-bit float\n",
    "x3 = x0.to(torch.float32) #Alternative way to cast to 32-bit float\n",
    "x4 = x0.to(torch.float64) #Alternative way to cast to 64-bit float\n",
    "print('x0:',x0.dtype)\n",
    "print('x1:',x1.dtype)\n",
    "print('x2:',x2.dtype)\n",
    "print('x3:',x3.dtype)\n",
    "print('x4:',x4.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0 shape is torch.Size([3, 3]), dtype is torch.float64\n",
      "x1 shape is torch.Size([3, 3]), dtype is torch.float64\n",
      "x2 shape is torch.Size([4, 5]), dtype is torch.float64\n",
      "x3 shape is torch.Size([6, 7]), dtype is torch.float64\n"
     ]
    }
   ],
   "source": [
    "x0 = torch.eye(3,dtype = torch.float64)# Shape (3,3), dtype torch.float64\n",
    "x1 = torch.zeros_like(x0)# Shape (3,3), dtype torch.float64\n",
    "x2 = x0.new_zeros(4,5)# Shape (4,5), dtype torch.float64\n",
    "x3 = torch.ones(6,7).to(x0)# Shape (6,7), dtype torch.float64\n",
    "print('x0 shape is %r, dtype is %r' % (x0.shape, x0.dtype))\n",
    "print('x1 shape is %r, dtype is %r' % (x1.shape, x1.dtype))\n",
    "print('x2 shape is %r, dtype is %r' % (x2.shape, x2.dtype))\n",
    "print('x3 shape is %r, dtype is %r' % (x3.shape, x3.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([ 0, 11, 22, 33, 44, 55, 66])\n",
      "1 tensor([22, 33, 44, 55])\n",
      "2 tensor([33, 44, 55, 66])\n",
      "3 tensor([ 0, 11, 22, 33])\n",
      "4 tensor([ 0, 11, 22, 33, 44, 55, 66])\n",
      "5 tensor([11, 44])\n",
      "6 tensor([ 0, 11, 22, 33, 44, 55])\n",
      "7 tensor([33, 55])\n"
     ]
    }
   ],
   "source": [
    "# Tensor indexing\n",
    "a = torch.tensor([0,11,22,33,44,55,66])\n",
    "print(0,a)     # Original tensor\n",
    "print(1,a[2:6])# Elements between index 2 and 5\n",
    "print(2,a[3:]) # Elements after index 3\n",
    "print(3,a[:4]) # Elements before index 4 \n",
    "print(4,a[:])  # All elements\n",
    "print(5,a[1:5:3]) # Every third element between indices 1 and 5\n",
    "print(6, a[:-1]) # All but last element\n",
    "print(7,a[-4::2]) # Every second element, starting from the fourth-last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor\n",
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n",
      "shape: torch.Size([3, 4])\n",
      "\n",
      "Single row:\n",
      "tensor([5, 6, 7, 8])\n",
      "tensor([5, 6, 7, 8])\n",
      "shape: torch.Size([4])\n",
      "\n",
      "Single column:\n",
      "tensor([ 2,  6, 10])\n",
      "shape: torch.Size([3])\n",
      "\\First two rows, last two columns: \n",
      "tensor([[ 2,  3],\n",
      "        [10, 11]])\n",
      "shape: torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "#Create the following rank 2 tensor with shape (3,4)\n",
    "#[[1,2,3,4]\n",
    "#[5,6,7,8]\n",
    "#[9,10,11,12]]\n",
    "a = torch.tensor([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
    "print('Original tensor')\n",
    "print(a)\n",
    "print('shape:',a.shape)\n",
    "\n",
    "#Get row 2, and all columns.\n",
    "print('\\nSingle row:')\n",
    "print(a[1,:])\n",
    "print(a[1]) \n",
    "print('shape:',a[1].shape)\n",
    "\n",
    "print('\\nSingle column:')\n",
    "print(a[:,1])\n",
    "print('shape:',a[:,1].shape)\n",
    "\n",
    "#Get the first two rows and the last three columns\n",
    "print('\\First two rows, last two columns: ')\n",
    "print(a[::2,1:3])\n",
    "print('shape:',a[::2,1:3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor\n",
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n",
      "\n",
      "Two ways of accessing a single row:\n",
      "tensor([5, 6, 7, 8]) torch.Size([4])\n",
      "tensor([[5, 6, 7, 8]]) torch.Size([1, 4])\n",
      "\n",
      "Two ways of accessing a single column:\n",
      "tensor([ 2,  6, 10]) torch.Size([3])\n",
      "tensor([[ 2],\n",
      "        [ 6],\n",
      "        [10]]) torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "#Create the following rank 2 tensor with shape(3,4)\n",
    "a = torch.tensor([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
    "print('Original tensor')\n",
    "print(a)\n",
    "\n",
    "row_r1 = a[1,:] # Rank 1 view of the second row of a\n",
    "row_r2 = a[1:2,:] #Rank 2 view of the second row of a\n",
    "print('\\nTwo ways of accessing a single row:')\n",
    "print(row_r1,row_r1.shape)\n",
    "print(row_r2,row_r2.shape)\n",
    "\n",
    "#We can make the samw distinction when accessing columns::\n",
    "col_r1 = a[:,1]\n",
    "col_r2 = a[:, 1:2]\n",
    "print('\\nTwo ways of accessing a single column:')\n",
    "print(col_r1, col_r1.shape)\n",
    "print(col_r2, col_r2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before mutating\n",
      "tensor([[1, 2, 3, 4],\n",
      "        [5, 6, 7, 8]])\n",
      "tensor([2, 3, 4])\n",
      "tensor([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "#Create a tensor, a slice, and a clone of a slice\n",
    "a = torch.tensor([[1,2,3,4],[5,6,7,8]])\n",
    "b = a[0, 1:]\n",
    "c = a[0, 1:].clone()\n",
    "print('Before mutating')\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor\n",
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n",
      "\n",
      "Reordered rows:\n",
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 1,  2,  3,  4],\n",
      "        [ 9, 10, 11, 12],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 5,  6,  7,  8]])\n",
      "\n",
      "Reordered columns:\n",
      "tensor([[ 4,  3,  2,  1],\n",
      "        [ 8,  7,  6,  5],\n",
      "        [12, 11, 10,  9]])\n"
     ]
    }
   ],
   "source": [
    "#Create the following rank 2 tensor with shape (3,4)\n",
    "#[[1,2,3,4]\n",
    "#[5,6,7,8]\n",
    "#[9,10,11,12]]\n",
    "a = torch.tensor([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
    "print('Original tensor')\n",
    "print(a)\n",
    "\n",
    "#Create a new tensor of shape (5,4 ) by reordering rows from a:\n",
    "#-First two rows same as the first row of a\n",
    "#-Third row is the same as the last row of a\n",
    "#-Fourth and Fifth rows are the same as the second row from a\n",
    "idx = [0,0,2,1,1] #index arrays can be Python lists of integers\n",
    "print('\\nReordered rows:')\n",
    "print(a[idx])\n",
    "\n",
    "#Create a new tensor of shape (3,4) by reversing the columns from a \n",
    "idx = torch.tensor([3,2,1,0])\n",
    "print('\\nReordered columns:')\n",
    "print(a[:,idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor\n",
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n",
      "\n",
      "Get the diagonal:\n",
      "tensor([ 1,  6, 11])\n",
      "\n",
      "After setting the diagonal:\n",
      "tensor([[11,  2,  3,  4],\n",
      "        [ 5, 22,  7,  8],\n",
      "        [ 9, 10, 33, 12]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
    "print('Original tensor')\n",
    "print(a)\n",
    "\n",
    "idx = [0,1,2]\n",
    "print('\\nGet the diagonal:')\n",
    "print(a[idx,idx])\n",
    "\n",
    "#Modify the diagonal\n",
    "a[idx,idx] = torch.tensor([11,22,33])\n",
    "print('\\nAfter setting the diagonal:')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor\n",
      "tensor([[ 1,  2,  3],\n",
      "        [ 4,  5,  6],\n",
      "        [ 7,  8,  9],\n",
      "        [10, 11, 12]])\n",
      "\n",
      "Select one element from each row:\n",
      "tensor([ 2,  6,  8, 10])\n",
      "\n",
      "After modifying one element from each row:\n",
      "tensor([[ 1,  0,  3],\n",
      "        [ 4,  5,  0],\n",
      "        [ 7,  0,  9],\n",
      "        [ 0, 11, 12]])\n"
     ]
    }
   ],
   "source": [
    "#Create a new tensor from which will select elements\n",
    "a = torch.tensor([[1,2,3],[4,5,6],[7,8,9],[10,11,12]])\n",
    "print('Original tensor')\n",
    "print(a)\n",
    "\n",
    "#Take on elements from each row of a:\n",
    "#from row 0, take element 1;\n",
    "#from row 1, take element 2;\n",
    "#from row 2, take element 1;\n",
    "#from row 3, take element 0;\n",
    "idx0 = torch.arange(a.shape[0])\n",
    "idx1 = torch.tensor([1,2,1,0])\n",
    "print('\\nSelect one element from each row:')\n",
    "print(a[idx0,idx1])\n",
    "\n",
    "#Now set each of those elements to zero\n",
    "a[idx0,idx1] = 0\n",
    "print('\\nAfter modifying one element from each row:')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "\n",
      "Mask tensor:\n",
      "tensor([[False, False],\n",
      "        [False,  True],\n",
      "        [ True,  True]])\n",
      "\n",
      "Selecting elements with the mask:\n",
      "tensor([4, 5, 6])\n",
      "\n",
      "After modifying with a mask:\n",
      "tensor([[0, 0],\n",
      "        [0, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "#Boolean tensor indexing\n",
    "a = torch.tensor([[1,2],[3,4],[5,6]])\n",
    "print('Original tensor')\n",
    "print(a)\n",
    "\n",
    "#Find the elements of a that are bigger than 3. The mask has the same shape as a,\n",
    "#where each element of mask tells whether the corresponding element of a is greater than three\n",
    "mask = (a>3)\n",
    "print('\\nMask tensor:')\n",
    "print(mask)\n",
    "\n",
    "#We can use the mask to construck a rank-1 tensor containing the elements of a that are selected by the mask\n",
    "print('\\nSelecting elements with the mask:')\n",
    "print(a[mask])\n",
    "\n",
    "#We can also use boolean masks to modify tensors; for example this sets all elements <=3 to zero:\n",
    "a[a <= 3] = 0\n",
    "print('\\nAfter modifying with a mask:')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[1, 2, 3, 4],\n",
      "        [5, 6, 7, 8]])\n",
      "shape: torch.Size([2, 4])\n",
      "\n",
      "Flatten tensor:\n",
      "tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "shape: torch.Size([8])\n",
      "\n",
      "Row vector:\n",
      "tensor([[1, 2, 3, 4, 5, 6, 7, 8]])\n",
      "shape: torch.Size([1, 8])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6],\n",
      "        [7],\n",
      "        [8]])\n",
      "shape: torch.Size([8, 1])\n",
      "\n",
      "Rank 3 tensor:\n",
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n",
      "shape: torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "#Reshaping operations\n",
    "x0 = torch.tensor([[1,2,3,4],[5,6,7,8]])\n",
    "print('Original tensor:')\n",
    "print(x0)\n",
    "print('shape:',x0.shape)\n",
    "\n",
    "#Flatten x0 into a rank 1 vector of shape (8,)\n",
    "x1 = x0.view(8)\n",
    "print('\\nFlatten tensor:')\n",
    "print(x1)\n",
    "print('shape:',x1.shape)\n",
    "\n",
    "#Convert x1 to a rank 2 \"row vector\" of shape(1,8)\n",
    "x2 = x1.view(1,8)\n",
    "print('\\nRow vector:')\n",
    "print(x2)\n",
    "print('shape:',x2.shape)\n",
    "\n",
    "#Convert x1 to a rank 2 \"column vector\" of shape(8,1)\n",
    "x3 = x2.view(8,1)\n",
    "print(x3)\n",
    "print('shape:',x3.shape)\n",
    "\n",
    "#Convert x1 to a rank 3 tensor of shape(2,2,2):\n",
    "x4 = x3.view(2,2,2)\n",
    "print('\\nRank 3 tensor:')\n",
    "print(x4)\n",
    "print('shape:',x4.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "x1:\n",
      "tensor([1, 2, 3, 4, 5, 6])\n",
      "x2:\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "#We can reuse these functions for tensors of different shapes\n",
    "x0 = torch.tensor([[1,2,3],[4,5,6]])\n",
    "x1 = x0.view(-1,)\n",
    "x2 = x0.view(-1,2)\n",
    "\n",
    "print('x0:')\n",
    "print(x0)\n",
    "\n",
    "print('x1:')\n",
    "print(x1)\n",
    "\n",
    "print('x2:')\n",
    "print(x2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x before modifying:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "x_flat before modifying:\n",
      "tensor([1, 2, 3, 4, 5, 6])\n",
      "\n",
      "x after modifying:\n",
      "tensor([[10, 20,  3],\n",
      "        [ 4,  5,  6]])\n",
      "x_flat after modifying:\n",
      "tensor([10, 20,  3,  4,  5,  6])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1,2,3],[4,5,6]])\n",
    "x_flat = x.view(-1)\n",
    "print('x before modifying:')\n",
    "print(x)\n",
    "print('x_flat before modifying:')\n",
    "print(x_flat)\n",
    "\n",
    "x[0,0] = 10\n",
    "x_flat[1] = 20\n",
    "\n",
    "print('\\nx after modifying:')\n",
    "print(x)\n",
    "print('x_flat after modifying:')\n",
    "print(x_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original matrix:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "Transposing with view DOES NOT WORK!\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "\n",
      "Transposed matrix\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "#Swapping axes\n",
    "x = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print('Original matrix:')\n",
    "print(x)\n",
    "print('\\nTransposing with view DOES NOT WORK!')\n",
    "print(x.view(3,2))\n",
    "print('\\nTransposed matrix')\n",
    "print(torch.t(x))\n",
    "print(x.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[[ 1,  2,  3,  4],\n",
      "         [ 5,  6,  7,  8],\n",
      "         [ 9, 10, 11, 12]],\n",
      "\n",
      "        [[13, 14, 15, 16],\n",
      "         [17, 18, 19, 20],\n",
      "         [21, 22, 23, 24]]])\n",
      "shape: torch.Size([2, 3, 4])\n",
      "\n",
      "Swap axes 1 and 2:\n",
      "tensor([[[ 1,  5,  9],\n",
      "         [ 2,  6, 10],\n",
      "         [ 3,  7, 11],\n",
      "         [ 4,  8, 12]],\n",
      "\n",
      "        [[13, 17, 21],\n",
      "         [14, 18, 22],\n",
      "         [15, 19, 23],\n",
      "         [16, 20, 24]]])\n",
      "torch.Size([2, 4, 3])\n",
      "\n",
      "Permute axes\n",
      "tensor([[[ 1, 13],\n",
      "         [ 2, 14],\n",
      "         [ 3, 15],\n",
      "         [ 4, 16]],\n",
      "\n",
      "        [[ 5, 17],\n",
      "         [ 6, 18],\n",
      "         [ 7, 19],\n",
      "         [ 8, 20]],\n",
      "\n",
      "        [[ 9, 21],\n",
      "         [10, 22],\n",
      "         [11, 23],\n",
      "         [12, 24]]])\n",
      "shape: torch.Size([3, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "#Create a tensor of shape(2,3,4)\n",
    "x0 = torch.tensor([\n",
    "    [[1,2,3,4],\n",
    "    [5,6,7,8],\n",
    "    [9,10,11,12]],\n",
    "    [[13,14,15,16],\n",
    "     [17,18,19,20],\n",
    "     [21,22,23,24]]])\n",
    "print('Original tensor:')\n",
    "print(x0)\n",
    "print('shape:',x0.shape)\n",
    "\n",
    "#Swap axes 1 and 2; shape is (2,4,3)\n",
    "x1 = x0.transpose(1,2)\n",
    "print('\\nSwap axes 1 and 2:')\n",
    "print(x1)\n",
    "print(x1.shape)\n",
    "\n",
    "#Permute axes; the argument(1,2,0)means;\n",
    "#-Make the old dimension 1 appear at dimension 0;\n",
    "#-Make the old dimension 2 appear at dimension 1;\n",
    "#-Make the old dimension 0 appear at dimension 2;\n",
    "x2 = x0.permute(1,2,0)\n",
    "print('\\nPermute axes')\n",
    "print(x2)\n",
    "print('shape:',x2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'RuntimeError'> view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n",
      "x1 shape: torch.Size([8, 3])\n",
      "x1 shape: torch.Size([8, 3])\n"
     ]
    }
   ],
   "source": [
    "x0 = torch.randn(2,3,4)\n",
    "try:\n",
    "    #This sequence of reshape operations will crash\n",
    "    x1 = x0.transpose(1,2).view(8,3)\n",
    "except RuntimeError as e:\n",
    "    print(type(e),e)\n",
    "    \n",
    "#We can slove this problem using either .contiguous or .reshape()\n",
    "x1 = x0.transpose(1,2).contiguous().view(8,3)\n",
    "x2 = x0.transpose(1,2).reshape(8,3)\n",
    "print('x1 shape:',x1.shape)\n",
    "print('x1 shape:',x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemtentwise sum:\n",
      "tensor([[ 6.,  8., 10., 12.]])\n",
      "tensor([[ 6.,  8., 10., 12.]])\n",
      "tensor([[ 6.,  8., 10., 12.]])\n",
      "\n",
      "Elemtentwise difference:\n",
      "tensor([[-4., -4., -4., -4.]])\n",
      "tensor([[-4., -4., -4., -4.]])\n",
      "tensor([[-4., -4., -4., -4.]])\n",
      "\n",
      "Elemtentwise product:\n",
      "tensor([[ 5., 12., 21., 32.]])\n",
      "tensor([[ 5., 12., 21., 32.]])\n",
      "tensor([[ 5., 12., 21., 32.]])\n",
      "\n",
      "Elemtentwise division:\n",
      "tensor([[0.2000, 0.3333, 0.4286, 0.5000]])\n",
      "tensor([[0.2000, 0.3333, 0.4286, 0.5000]])\n",
      "tensor([[0.2000, 0.3333, 0.4286, 0.5000]])\n",
      "\n",
      "Elemtentwise power:\n",
      "tensor([[1.0000e+00, 6.4000e+01, 2.1870e+03, 6.5536e+04]])\n",
      "tensor([[1.0000e+00, 6.4000e+01, 2.1870e+03, 6.5536e+04]])\n",
      "tensor([[1.0000e+00, 6.4000e+01, 2.1870e+03, 6.5536e+04]])\n"
     ]
    }
   ],
   "source": [
    "#Tensor operations\n",
    "#Elementwise operations\n",
    "x = torch.tensor([[1,2,3,4]],dtype = torch.float32)\n",
    "y = torch.tensor([[5,6,7,8]],dtype = torch.float32)\n",
    "\n",
    "#Elementwise sum; all give the same result\n",
    "print('Elemtentwise sum:')\n",
    "print(x+y)\n",
    "print(torch.add(x,y))\n",
    "print(x.add(y))\n",
    "\n",
    "#Elementwise difference\n",
    "print('\\nElemtentwise difference:')\n",
    "print(x-y)\n",
    "print(torch.sub(x,y))\n",
    "print(x.sub(y))\n",
    "\n",
    "#Elementwise product\n",
    "print('\\nElemtentwise product:')\n",
    "print(x*y)\n",
    "print(torch.mul(x,y))\n",
    "print(x.mul(y))\n",
    "\n",
    "#Elementwise division\n",
    "print('\\nElemtentwise division:')\n",
    "print(x/y)\n",
    "print(torch.div(x,y))\n",
    "print(x.div(y))\n",
    "\n",
    "#Elementwise power\n",
    "print('\\nElemtentwise power:')\n",
    "print(x**y)\n",
    "print(torch.pow(x,y))\n",
    "print(x.pow(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square root:\n",
      "tensor([[1.0000, 1.4142, 1.7321, 2.0000]])\n",
      "tensor([[1.0000, 1.4142, 1.7321, 2.0000]])\n",
      "n\\Trig functions:\n",
      "tensor([[ 0.8415,  0.9093,  0.1411, -0.7568]])\n",
      "tensor([[ 0.8415,  0.9093,  0.1411, -0.7568]])\n",
      "tensor([[ 0.5403, -0.4161, -0.9900, -0.6536]])\n",
      "tensor([[ 0.5403, -0.4161, -0.9900, -0.6536]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1,2,3,4]],dtype=torch.float32)\n",
    "print('Square root:')\n",
    "print(torch.sqrt(x))\n",
    "print(x.sqrt())\n",
    "\n",
    "print('n\\Trig functions:')\n",
    "print(torch.sin(x))\n",
    "print(x.sin())\n",
    "print(torch.cos(x))\n",
    "print(x.cos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n",
      "Sum over entire tensor:\n",
      "tensor(21.)\n",
      "tensor(21.)\n",
      "\n",
      "Sum of each row:\n",
      "tensor([5., 7., 9.])\n",
      "tensor([5., 7., 9.])\n",
      "\n",
      "Sum of each column\n",
      "tensor([ 6., 15.])\n",
      "tensor([ 6., 15.])\n"
     ]
    }
   ],
   "source": [
    "#Reduction operations\n",
    "x = torch.tensor([[1,2,3],\n",
    "                 [4,5,6]],dtype=torch.float32)\n",
    "print('Original tensor:')\n",
    "print(x)\n",
    "\n",
    "print('\\nSum over entire tensor:')\n",
    "print(torch.sum(x))\n",
    "print(x.sum())\n",
    "\n",
    "print('\\nSum of each row:')\n",
    "print(torch.sum(x,dim=0))\n",
    "print(x.sum(dim=0))\n",
    "\n",
    "print('\\nSum of each column')\n",
    "print(torch.sum(x,dim=1))\n",
    "print(x.sum(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[2., 4., 3., 5.],\n",
      "        [3., 3., 5., 2.]])\n",
      "tensor([[2., 4., 3., 5.],\n",
      "        [3., 3., 5., 2.]]) torch.Size([2, 4])\n",
      "\n",
      "Overall minimum: tensor(2.)\n",
      "\n",
      "Minimum along each column:\n",
      "values: tensor([2., 3., 3., 2.])\n",
      "idxs: tensor([0, 1, 0, 1])\n",
      "\n",
      "Minimum along each row:\n",
      "values: tensor([2., 2.])\n",
      "idxs: tensor([0, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[2,4,3,5],[3,3,5,2]],dtype=torch.float32)\n",
    "print('Original tensor:')\n",
    "print(x)\n",
    "print(x,x.shape)\n",
    "\n",
    "#Finding the overall minimum only returns a single value\n",
    "print('\\nOverall minimum:', x.min())\n",
    "\n",
    "col_min_vals,col_min_idxs = x.min(dim=0)\n",
    "print('\\nMinimum along each column:')\n",
    "print('values:', col_min_vals)\n",
    "print('idxs:', col_min_idxs)\n",
    "\n",
    "row_min_vals,row_min_idxs = x.min(dim=1)\n",
    "print('\\nMinimum along each row:')\n",
    "print('values:', row_min_vals)\n",
    "print('idxs:', row_min_idxs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 10, 3, 64, 64])\n",
      "torch.Size([128, 3, 64, 64])\n",
      "torch.Size([128, 3, 64])\n",
      "torch.Size([128, 1, 64])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(128,10,3,64,64)\n",
    "print(x.shape)\n",
    "\n",
    "x = x.mean(dim=1)\n",
    "print(x.shape)\n",
    "\n",
    "x = x.sum(dim=2)\n",
    "print(x.shape)\n",
    "\n",
    "x = x.mean(dim=1,keepdim=True)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot products:\n",
      "tensor(219.)\n",
      "tensor(219.)\n",
      "\n",
      "Matrix-matrix product:\n",
      "tensor([[19., 22.],\n",
      "        [43., 50.]])\n",
      "tensor([[19., 22.],\n",
      "        [43., 50.]])\n",
      "\n",
      "Matrix-vector product with torch.mv(rank 1 output)\n",
      "tensor([29., 67.])\n",
      "tensor([29., 67.])\n"
     ]
    }
   ],
   "source": [
    "#Matrix operations\n",
    "v = torch.tensor([9,10],dtype=torch.float32)\n",
    "w = torch.tensor([11,12],dtype=torch.float32)\n",
    "\n",
    "print('Dot products:')\n",
    "print(torch.dot(v,w))\n",
    "print(v.dot(w))\n",
    "\n",
    "x = torch.tensor([[1,2],[3,4]],dtype=torch.float32)\n",
    "y = torch.tensor([[5,6],[7,8]],dtype=torch.float32)\n",
    "print('\\nMatrix-matrix product:')\n",
    "print(torch.mm(x,y))\n",
    "print(x.mm(y))\n",
    "\n",
    "print('\\nMatrix-vector product with torch.mv(rank 1 output)')\n",
    "print(torch.mv(x,v))\n",
    "print(x.mv(v))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2,  2,  4],\n",
      "        [ 5,  5,  7],\n",
      "        [ 8,  8, 10],\n",
      "        [11, 11, 13]])\n"
     ]
    }
   ],
   "source": [
    "#Broadcasting\n",
    "x = torch.tensor([[1,2,3],[4,5,6],[7,8,9],[10,11,12]])\n",
    "v = torch.tensor([1,0,1])\n",
    "y = torch.zeros_like(x)\n",
    "\n",
    "for i in range(4):\n",
    "    y[i,:] = x[i,:]+v\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 1],\n",
      "        [1, 0, 1],\n",
      "        [1, 0, 1],\n",
      "        [1, 0, 1]])\n"
     ]
    }
   ],
   "source": [
    "vv = v.repeat((4,1))\n",
    "print(vv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2,  2,  4],\n",
      "        [ 5,  5,  7],\n",
      "        [ 8,  8, 10],\n",
      "        [11, 11, 13]])\n"
     ]
    }
   ],
   "source": [
    "y = x + vv\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2,  2,  4],\n",
      "        [ 5,  5,  7],\n",
      "        [ 8,  8, 10],\n",
      "        [11, 11, 13]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1,2,3],[4,5,6],[7,8,9],[10,11,12]])\n",
    "v = torch.tensor([1,0,1])\n",
    "y = x+v\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4,  5],\n",
      "        [ 8, 10],\n",
      "        [12, 15]])\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([1,2,3])\n",
    "w = torch.tensor([4,5])\n",
    "print(v.view(3,1) * w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python can use GPUs!\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available:\n",
    "    print('Python can use GPUs!')\n",
    "else:\n",
    "    print('Python cannot use GPUs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0 device: cpu\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3f09f8239052>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Move it to the GPU using .to()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x1 device:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m             raise RuntimeError(\n\u001b[1;32m    185\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             raise AssertionError(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "x0 = torch.tensor([[1,2],[3,4]], dtype=torch.float32)\n",
    "print('x0 device:', x0.device)\n",
    "\n",
    "# Move it to the GPU using .to()\n",
    "x1 = x0.to('cuda')\n",
    "print('x1 device:', x1.device)\n",
    "\n",
    "# Move it to the GPU using .cuda()\n",
    "x2 = x0.cuda()\n",
    "print('x2 device:', x2.device)\n",
    "\n",
    "# Move it back to the CPU using .to()\n",
    "x3 = x1.to('cpu')\n",
    "print('x3 device:', x3.device)\n",
    "\n",
    "# Move it back to the CPU using .cpu()\n",
    "x4 = x2.cpu()\n",
    "print('x4 device:', x4.device)\n",
    "\n",
    "# We can construct tensors directly on the GPU as well\n",
    "y = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float64, device='cuda')\n",
    "print('y device / dtype:', y.device, y.dtype)\n",
    "\n",
    "# Calling x.to(y) where y is a tensor will return a copy of x with the same\n",
    "# device and dtype as y\n",
    "x5 = x0.to(y)\n",
    "print('x5 device / dtype:', x5.device, x5.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-643e866f111c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mb_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0ma_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma_cpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mb_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb_cpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m             raise RuntimeError(\n\u001b[1;32m    185\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             raise AssertionError(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "a_cpu = torch.randn(10000, 10000, dtype=torch.float32)\n",
    "b_cpu = torch.randn(10000, 10000, dtype=torch.float32)\n",
    "\n",
    "a_gpu = a_cpu.cuda()\n",
    "b_gpu = b_cpu.cuda()\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "t0 = time.time()\n",
    "c_cpu = a_cpu + b_cpu\n",
    "t1 = time.time()\n",
    "c_gpu = a_gpu + b_gpu\n",
    "torch.cuda.synchronize()\n",
    "t2 = time.time()\n",
    "\n",
    "# Check that they computed the same thing\n",
    "diff = (c_gpu.cpu() - c_cpu).abs().max().item()\n",
    "print('Max difference between c_gpu and c_cpu:', diff)\n",
    "\n",
    "cpu_time = 1000.0 * (t1 - t0)\n",
    "gpu_time = 1000.0 * (t2 - t1)\n",
    "print('CPU time: %.2f ms' % cpu_time)\n",
    "print('GPU time: %.2f ms' % gpu_time)\n",
    "print('GPU speedup: %.2f x' % (cpu_time / gpu_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8(tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
